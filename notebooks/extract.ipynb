{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7ee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.db_connection import DatabaseConnection\n",
    "\n",
    "PATH = \"/home/mohamed/Desktop/data-engineering-projects/Covid-19-Data-Pipeline/data\"\n",
    "\n",
    "\n",
    "def read_data(file_name) -> pd.DataFrame:\n",
    "    full_path = PATH + file_name + \".csv\"\n",
    "    row_data = pd.read_csv(full_path, quotechar='\"', low_memory=False)\n",
    "    return row_data\n",
    "\n",
    "\n",
    "def process_row_data(row_data: pd.DataFrame, file_date):\n",
    "    row_data[\"ingested_at\"] = file_date\n",
    "    return row_data\n",
    "\n",
    "\n",
    "def load_row_into_db(row_data: pd.DataFrame):\n",
    "    db_connection = DatabaseConnection()\n",
    "\n",
    "    row_data.columns = row_data.columns.str.lower()  # Fix columns first\n",
    "    db_connection.load_dataframe_into_db(row_data, \"bronze\", \"covid\")\n",
    "\n",
    "\n",
    "def get_date_from_file_name(file_name: str) -> str:\n",
    "    return file_name.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dd94465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_bronze(BASE):\n",
    "    to_load_file_name = get_date_from_file_name(BASE)\n",
    "    row_data = read_data(to_load_file_name)\n",
    "    row_data = process_row_data(row_data, to_load_file_name)\n",
    "    load_row_into_db(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb4429e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_to_bronze' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_data_to_bronze\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01-02-2021.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data_to_bronze' is not defined"
     ]
    }
   ],
   "source": [
    "load_data_to_bronze(\"01-02-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43004e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "PATH = \"/home/mohamed/Desktop/data-engineering-projects/Covid-19-Data-Pipeline/data/\"\n",
    "\n",
    "\n",
    "def read_data(file_name) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read CSV file and drop exception incase if reading the file failed\n",
    "    \"\"\"\n",
    "    full_path = PATH + file_name + \".csv\"\n",
    "    print(f\"FULL_PATHH: {full_path}\")\n",
    "    try:\n",
    "        row_data = pd.read_csv(full_path, quotechar='\"', low_memory=False)\n",
    "\n",
    "        if row_data.empty:\n",
    "            raise ValueError(\"The dataset is empty.\")\n",
    "\n",
    "        return row_data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file {file_name} is not exist\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(\"the file is corupted or empty\")\n",
    "    except Exception as e:\n",
    "        raise type(e)(f\"Failed to read the dataframe{e}\")\n",
    "\n",
    "\n",
    "def normalize_dataframe_columns_to_lowercase(row_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Turn the columns name of the dataset to lowercase to avoid any mismatch with the database columns name\n",
    "    \"\"\"\n",
    "    if row_data.shape[1] == 0:\n",
    "        raise pd.errors.EmptyDataError(\"Dataframe is empty.\")\n",
    "\n",
    "    to_process = row_data.copy()\n",
    "    to_process.columns = to_process.columns.str.strip().str.lower()\n",
    "    return to_process\n",
    "\n",
    "\n",
    "def process_row_data(row_data: pd.DataFrame, file_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the row data that read from the source and add ingested_at date for incremental load and processing\n",
    "    to avoid full scan / processing.\n",
    "    \"\"\"\n",
    "    to_process = row_data.copy()\n",
    "\n",
    "    to_process[\"ingested_at\"] = file_date\n",
    "    return to_process\n",
    "\n",
    "\n",
    "def load_row_into_db(row_data: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Load the read dataset from source as it as after add new column ( ingested_at ) for delta and incremental processing.\n",
    "    Raise database exception incase of failure of storing the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with DatabaseConnection() as db_connection:\n",
    "            total_inserted = db_connection.load_dataframe_into_db(\n",
    "                row_data, \"bronze\", \"covid\"\n",
    "            )\n",
    "\n",
    "        return total_inserted\n",
    "\n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"An error happened during storing the dataset into the database {e}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_date_from_file_name(file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the date of the file by processing the filename and extract the date from the filename.\n",
    "    in date format of day-month-year\n",
    "    \"\"\"\n",
    "\n",
    "    content = file_name.split(\".\")\n",
    "\n",
    "    if len(content) != 2:\n",
    "        raise ValueError(\"The file name not as expected DD-MM-YYYY\")\n",
    "\n",
    "    file_date = parse(content[0]).strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    file_name = file_date + \".\" + content[1]\n",
    "\n",
    "    pattern = r\"^\\d{2}-\\d{2}-\\d{4}\\.csv$\"\n",
    "\n",
    "    if not re.match(pattern, file_name):\n",
    "        raise ValueError(\"The file name format not as expected.\")\n",
    "\n",
    "    return file_date\n",
    "\n",
    "\n",
    "def run_extraction(file_name) -> dict:\n",
    "    \"\"\"\n",
    "    Organizing the extraction process by run all the functions in order\n",
    "    \"\"\"\n",
    "\n",
    "    to_load_file_name = get_date_from_file_name(file_name)\n",
    "    loaded_data = read_data(to_load_file_name)\n",
    "    row_data = normalize_dataframe_columns_to_lowercase(loaded_data)\n",
    "    row_data = process_row_data(row_data, to_load_file_name)\n",
    "    total_inserted = load_row_into_db(row_data)\n",
    "\n",
    "    # Extraction Information\n",
    "\n",
    "    extraction_info = {\n",
    "        \"file_name\": file_name,\n",
    "        \"rows_read\": len(row_data),\n",
    "        \"loaded_data\": total_inserted,\n",
    "        \"status\": \"success\",\n",
    "    }\n",
    "\n",
    "    return extraction_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eeba7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-2021'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = get_date_from_file_name(\"01-03-2021.csv\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df25f006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL_PATHH: /home/mohamed/Desktop/data-engineering-projects/Covid-19-Data-Pipeline/data/03-01-2021.csv\n"
     ]
    }
   ],
   "source": [
    "loaded = read_data(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6997c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
